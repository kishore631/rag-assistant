ğŸ¤– GenAI RAG Assistant â€“ Document-Based Chat System

A production-style Retrieval-Augmented Generation (RAG) assistant that answers user questions using intelligent document retrieval and cosine similarity ranking.

Built with:

âš™ï¸ Node.js + Express (Backend)

âš›ï¸ React (Vite) (Frontend)

ğŸ§  Custom Embedding Logic

ğŸ“Š Cosine Similarity Algorithm

ğŸš€ Deployed on Render & Vercel

ğŸ“Œ Problem Statement

Build a production-style GenAI-powered Chat Assistant that:

Converts documents into embeddings

Stores them in a vector store

Performs similarity search

Injects relevant context

Returns grounded responses

This system demonstrates real embedding-based retrieval, not keyword matching or hardcoded answers.

ğŸ§  How The System Works
1ï¸âƒ£ Document Ingestion

Documents stored in docs.json

ingest.js generates embeddings

Vector store saved locally as vector_store.json

2ï¸âƒ£ Embedding Generation

Custom embedding logic includes:

Lowercasing

Stopword removal

Basic stemming

Synonym normalization

Word frequency vector creation

No paid APIs are used.

3ï¸âƒ£ Similarity Search

Cosine similarity between query and document vectors

Title boosting for better relevance

Ranked document scoring

Threshold-based fallback handling

4ï¸âƒ£ Intelligent Response Logic

Greeting detection

Ranked top document retrieval

Confidence percentage scoring

Graceful fallback for weak matches

ğŸ› ï¸ Tech Stack
Backend

Node.js

Express.js

Custom Embedding Engine

Cosine Similarity Algorithm

Frontend

React (Vite)

Responsive Chat UI

Dark Mode Toggle

Confidence Badge

Deployment

Backend â†’ Render

Frontend â†’ Vercel

GitHub for Version Control

ğŸ“‚ Project Structure
rag-assistant/
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ docs.json
â”‚   â”‚   â””â”€â”€ vector_store.json (generated)
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â””â”€â”€ chat.js
â”‚   â”œâ”€â”€ scripts/
â”‚   â”‚   â””â”€â”€ ingest.js
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ embed.js
â”‚   â”‚   â””â”€â”€ cosine.js
â”‚   â””â”€â”€ server.js
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â””â”€â”€ App.jsx
â”‚
â””â”€â”€ README.md
âš™ï¸ Installation & Setup
1ï¸âƒ£ Clone Repository
git clone https://github.com/your-username/rag-assistant.git
cd rag-assistant
2ï¸âƒ£ Backend Setup
cd backend
npm install
node scripts/ingest.js
node server.js

Server runs at:

http://localhost:5000
3ï¸âƒ£ Frontend Setup
cd frontend
npm install
npm run dev

Frontend runs at:

http://localhost:5173
ğŸŒ Deployment Guide
Backend (Render)

Create Web Service

Build Command: npm install

Start Command: npm start

Frontend (Vercel)

Framework: Vite

Root Directory: frontend

Build Command: npm run build

Output Directory: dist

ğŸ“Š Features

Multi-document retrieval

Synonym-aware embedding

Ranked similarity search

Confidence scoring

Greeting detection

Dark mode toggle

Modern UI

Production-ready architecture

ğŸ”® Future Improvements

Top-K document retrieval

Hybrid TF-IDF + embedding scoring

LLM-based generative responses

Database-based vector storage

Authentication system

ğŸ‘¨â€ğŸ’» Author

GIDIGI VENKATA KISHORE
B.Tech Computer Science (2025)
AI & Machine Learning Enthusiast